{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Data with Numpy, Scipy, and Pandas\n",
    "## Topics\n",
    "\n",
    "- Array data types with numpy\n",
    "- Basic statistical analysis with numpy tools\n",
    "- Introduction to the scipy packages\n",
    "- Pandas for data manipulation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Today we're covering libraries that are an important part of the core Python data stack - numpy, scipy, and pandas.\n",
    "\n",
    "**Numpy** is a library for fast numerical processing on 1-dimensional (arrays) or 2-dimensional (tables/matrics) data types.\n",
    "\n",
    "**Scipy** contains more advanced tools for statistics and regression.\n",
    "\n",
    "**Pandas** introduces the copy of a DataFrame to Python (familiar to those of you coming from R)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Basics\n",
    "Numerical Python is a powerful library of functions, methods, and data types we can used to analyze our data. Unforunately for those of us whose heads continue to spin in a crash-course of syntax, it also uses a different set of rules. I hope you'll understand why when you see the power and speed NumPy's data types afford us. Let's start off creating some empty arrays, which look sorta like lists, and are in fact vectors.\n",
    "\n",
    "They differ in a few fundamental ways from lists:\n",
    "\n",
    "1. **Arrays cannot be of mixed types.** They can be all integers, floats, strings, logical (or boolean) values, or other immutable values. But they cannot be some characters, some numbers, or any other olio of data types. They also cannot contain mutable types such as lists. So, we can have a list of lists, but not an array of lists. We can, however, have an array of arrays (sortof). Which brings us to:\n",
    "2. Arrays can be multidimensional, but they must be rectangular. You can have a list of lists, where the first interior list is 3 elements long, the second 5, and the third 12, but for your multidemsional arrays, every row must have the same number of columns.\n",
    "3. We can perform vector operations on them, which can be algebraic functions (like a dot product), or simple replacements of values in a slice of the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays\n",
    "Here's one way: start with a list and turn it into an array with the array method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [0] * 40\n",
    "print type(a)\n",
    "a = np.array(a)\n",
    "print type(a)\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have an array a of 1 row and 40 columns with zeros. But there's a better way to get a vector of zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's how to declare something that's not all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(40)\n",
    "print a\n",
    "type(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the int type.\n",
    "\n",
    "What if we want a float? There's a couple ways to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(40, dtype=float)  # Explicitly tell it to use floats\n",
    "print type(a[0])\n",
    "\n",
    "a = np.arange(40.0)  # If you give it a float for the length, it will automatically use floats\n",
    "print type(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with range(), you can also give arange() more parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(40, 50)  # Start and Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(40, 50, 2) # Start, Stop, and increment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(40,50,.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said above, you can have arrays with more than one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(  (10, 10)   ) # Note the inner set of parentheses. (Rows, Columns)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can even modify a particular element with the same syntax, or a subtly different syntax, as our list-of-lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[5,5] = 3  # choose row, then column\n",
    "a[6,6] = 42  # Only one set of []\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even add a number to a specific position using the '+=' notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[6,6]+=10 # Add 10 to the nth row, nth column\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the coolest thing I've shown you isn't really that exciting: a range function that can have floats. The real power of arrays is the ability to have one statement affect a large chunk of an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1,:] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,0] = 7\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a == 0] = -1\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pause for a moment and think about how we would do this with a for loop in lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of lists of all zeros\n",
    "LoL = [[0]*10 for i in range(10)] #LoL - List of Lists\n",
    " \n",
    "# Set entries in row 1 to 1\n",
    "for i, elem in enumerate(LoL[1]):\n",
    "    LoL[1][i] = 1\n",
    "\n",
    "# Set entries in column zero to 7\n",
    "for L in LoL:\n",
    "    L[0] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take slices of arrays, just as if they were lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "a[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you can see the advantage of the array syntax. But wait, there's more! Act now, and we'll throw in math operations for free!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Math with Arrays\n",
    "We can do math on many values at once with arrays, no for loop required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0, 100, 2)\n",
    "b = np.arange(50)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b # Pairwise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a * b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(a, b) # or can take the dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics with Numpy\n",
    "\n",
    "NumPy is **huge**, with around 1200 pages of [reference documentation](http://docs.scipy.org/doc/numpy/reference/index.html), but all of you will, at some point, use some basic statistics to get a feel for your data. So let's make sure we hit some of those functions:\n",
    "\n",
    "### Random distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.uniform(0, 100, 10) # Low, High, Size of output\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.uniform(0, 100, (3,3)) # Can also give a shape for the third argument\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(0, 1, 10) # Normal distribution with mean=0, std=1, 10 samples\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(5, 3, 1000)  # Draw 1000 numbers from the standard normal distribution with mean 5 and std 3\n",
    "np.mean(a) # Calculate the mean of this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a) # Standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating on 2d arrays\n",
    "One of the areas where numpy really shines is its ability to quickly operate along an axis of a 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((5,3))# 5 rows, 3 columns\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum()  # Sum over all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=0)  # Sum across all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows are axis 0 and Columns are axis 1.  The order here makes sense because its the same order that you use when indexing an array, rows first - then columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum(axis=1) # Sum across all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Numpy Arrays for Selection and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(10, dtype=bool)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing and mass-assignment still work\n",
    "a[2:5] = True\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ~ character inverts the boolean array\n",
    "b = ~a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating \"&\" and \"|\"\n",
    "a = np.array([True, False, True])\n",
    "b = np.array([False, False, True])\n",
    "\n",
    "print \"A and B\"\n",
    "print a & b\n",
    "\n",
    "print \"A or B\"\n",
    "print a | b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using boolean expressions, you can specifically read out or assign to pieces of the array based on the values in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10)\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_less_than_zero = data < 0\n",
    "print data_less_than_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data_less_than_zero] = 0   # Replace all values less than zero, with zero\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(10)\n",
    "data[data < 0] = 0  # You could also do this without a temporary variable (data_less_than_zero)\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(20,5)*10 # Random data from 0 to 10\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show me the mean of each row\n",
    "row_means = data.mean(axis=1)\n",
    "print row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give me a subset of the data matrix, containing only rows with a mean > 5 and the second column < 4 \n",
    "mean_greater_five = data.mean(axis=1) > 5\n",
    "print \"mean_greater_five: \", mean_greater_five\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matrix = data[mean_greater_five, :]\n",
    "print\n",
    "print \"new_matrix\"\n",
    "print new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR, all in one line - without a temporary variable\n",
    "new_matrix = data[ (data.mean(axis=1) > 5) ]\n",
    "print\n",
    "print \"new_matrix\"\n",
    "print new_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Numpy?\n",
    "1. Avoid writing loops (don't re-invent the wheel)\n",
    "2. **Efficient Computation**\n",
    "\n",
    "Regarding the second point, numpy is useful because operations using it are many times faster than their pure Python implementations.  This is because numpy processes arrays using code written in 'low-level' languages like C or Fortran.  These languages are much more tedious to write programs in, but run much faster than a 'high-level' language like Python.  However, by using Python to call functions written by other people in low-level languages, you can get the best of both worlds.\n",
    "\n",
    "**Quick performance comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Setup Create a 1000 x 1000 list of lists (2d matrix)\n",
    "N_ROWS = 1000\n",
    "N_COLS = 1000\n",
    "python_matrix = [[1]*N_COLS for i in range(N_ROWS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Add 1 to every entry in the matrix\n",
    "for i in xrange(N_ROWS):\n",
    "    for j in xrange(N_COLS):\n",
    "        python_matrix[i][j] += + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# List comprehensions help...a little\n",
    "result = [[x+1 for x in row] for row in python_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit numpy_matrix = np.zeros((1000, 1000))\n",
    "numpy_matrix += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because numpy is able to know that everything is going to be a float, it can do a lot of optimizations to the arrays that it wouldn't be able to do if each element could, conceivably be a different type. Furthermore, a lot of the time is spent checking to make sure i and j aren't too big or small for the size of the lists, while the numpy code just loads the size of the array once and never checks again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy and Fitting\n",
    "\n",
    "SciPy (pronounced \"Sigh Pie\") is a collection of libraries that builds on NumPy, and has lots of convenient, fast functions for working with large amounts of scientific data. It's slightly smaller than NumPy, with only 900-odd pages of documentation. That includes sections on integrating C or Fortran code into Python, which is way outside the scope of this course, but if you ever do get to the point where you need a super-efficient implementation of something, you're covered. Especially in the one-off nature of academic science, you're often better served spending less time writing code that takes longer to run, compared to spending lots and lots of time writing code that runs slightly faster.\n",
    "\n",
    "The [stats](http://docs.scipy.org/doc/scipy/reference/tutorial/stats.html) module of SciPy has functions for even more statistical distributions, statistical tests, and other assorted functions that a good statistician might need. As an example, let's see how we might use the [linregress](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html#scipy.stats.linregress) function, which does a linear regression on some data. Linear regression is the process of finding a line that minimizes the sum of the square of the vertical distances from each point to the line.\n",
    "\n",
    "First, we'll set up some noisy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "slope = 0.5\n",
    "intercept = -10\n",
    "\n",
    "x = np.arange(0, 100)\n",
    "y = slope*x + intercept\n",
    "noise = 5 * np.random.normal(0, 1, size=len(x))\n",
    "\n",
    "y = y + noise\n",
    "\n",
    "# Plot the line - more detials on this are covered in a later lecture\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, using a bit of linear algebra, we can actually compute the best fit linear coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(x)\n",
    " \n",
    "m = (n * sum(x * y) - sum(x) * sum(y)) / (n * sum(x**2) - (sum(x))**2)\n",
    "b = (sum(y) - m * sum(x))/n\n",
    "r = (n * sum(x * y) - sum(x) * sum(y)) / np.sqrt((n*sum(x**2) - sum(x)**2)\n",
    "* (n * sum(y**2) - sum(y)**2))\n",
    " \n",
    "print m, b, r\n",
    "\n",
    "y2 = m*x + b\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,y2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us pretty much the right result, but it was kind of a pain to type in. If only the libraries had some sort of function that could do linear regression for us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    " \n",
    "r_slope, r_int, r_rval, r_pval, r_stderr = stats.linregress(x, y)\n",
    " \n",
    "print \"Regression Slope: \", r_slope\n",
    "print \"Regression Intercept: \", r_int\n",
    "print \"Regression correlation: \", r_rval\n",
    "print \"R^2:, \", r_rval**2\n",
    "print \"p(slope is 0): \", r_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if you want to just compute the correlation, there's a function for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "result = pearsonr(x, y)\n",
    "print \"Pearson: \", result\n",
    "\n",
    "print\n",
    "\n",
    "result = spearmanr(x, y)\n",
    "print \"Spearman: \", result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy can also be used to calculate a t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Generate two sets of samples from the normal distribution\n",
    "\n",
    "group1 = np.random.normal(1.3, 1, 1000)\n",
    "group2 = np.random.normal(1, 1, 1000)\n",
    "\n",
    "# Some plotting code (ignore for now)\n",
    "plt.hist(group1, 100, (-5, 5), alpha=.6)\n",
    "plt.hist(group2, 100, (-5, 5), alpha=.6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "result = ttest_ind(group1, group2)\n",
    "print \"P =\", result.pvalue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Part 1 - Break for Exercises\n",
    "\n",
    "<ol>\n",
    "<li style=\"margin-bottom: 20px\"><b>Writing Mathematical Functions</b>\n",
    "    <ol>\n",
    "    <li>Write a function that accepts an array of floats as inputs. Return an array where every value of the input array has been divided by 1.5.</li>\n",
    "    <li>Use a random function (uniform or normal) to generate an array of floats. Write a function that accepts this array, and returns a list of values that are more than one standard deviation greater or less than the mean of the array.</li>\n",
    "    <li>Write a function that estimates a p-value from the exponential distribution (another distribution in numpy).  The function should take a number as an input (lets call it x), and return an estimate at the probability that a number drawn from the exponential distribution will be equal to or greater than x.  <br/><br/>To do this, generate many samples from the exponential distribution (use the default scale=1.0), count the number of samples greater than x, and divide the result by the number of samples you generated.  <br/><br/>Don't use a loop to count the number of samples greater than x.  Instead look at what happens when you use np.sum() on a boolean array, or read about the method np.count_nonzero().<br/><br/>Calling your function should look like this:<br/>\n",
    "    ```\n",
    "    out = my_function(3)\n",
    "print out #prints 0.050316 (or close to this number)\n",
    "    ```</li>\n",
    "    </ol>\n",
    "</li>\n",
    "\n",
    "<li><b>Strings to arrays</b><br/>\n",
    "So we had this idea that we might be able to find a periodicity in the spacing of pyrimidine residues downstream of the termination site in Rho dependent genes (by and large, we don't). Nevertheless:\n",
    "    <ol>\n",
    "    <li>Make a function that takes a DNA string as input (Only G, C, A, or T's) and an arbitrary substring (e.g. \"CT\"). The function should find all locations of the substring in the string and return it as an array.<br/><i>For Example:</i><br/>\n",
    "    ```\n",
    "    a = find_substring(\"GCACTTGCACGTACGCCGT\", \"AC\") \n",
    "# output a contains [2, 8, 12] (or a numpy array with these values)\n",
    "    ```</li>\n",
    "    <li>Using the result of find_substring from (a), find the distance between each pair of adjacent substrings. (i.e. How many basepairs separate each position where we found the subtring.) Check if a numpy method does this.<br/><i>For Example:</i><br/>\n",
    "    ```\n",
    "    differences = find_differences(a)\n",
    "# differences contains [6, 4]\n",
    "    ```</li>\n",
    "    <li>Use the fasta-parser you've written to read the S.cerevisiae genome fasta file from Lecture 1.1 . Then, using the functions in part (a) and (b), generate a full list of the spacings between 'CT' nucleotide pairs for each chromosome and return an array of the differences between adjacent positions</li>\n",
    "<li>Using numpy, compute the histogram of these spacings (we'll show you how to plot them later).  Use Google (or the documentation we linked above) to look up the right numpy function and how to use it.</li></ol></li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "Pandas is a great tool for working with data in Python.  The main object in Pandas you will use is the **DataFrame**.  It has several advantages over numpy ndarrays:\n",
    "\n",
    "1. Allows mixed-types\n",
    "2. Label-based row-column indices\n",
    "3. Easy database-like operations (merge, join, groupby, sort, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # Pandas is usually abbreviated this way in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play around with Pandas, first let's read in some data from file.\n",
    "\n",
    "In the nycflights13 folder, we have a set of files with data on all the flights that departed NYC airports in 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data from a tab-delimited text-file\n",
    "planes = pd.read_table(\"nycflights13/planes.txt\")\n",
    "\n",
    "# Pandas also has read_excel, read_csv, read_json, read_sql and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's this 'plane' variable have in it?\n",
    "print type(planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is it?\n",
    "print planes.shape  # same as for numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the column labels?\n",
    "print planes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the row labels?\n",
    "print planes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three important types that are used by DataFrames:\n",
    "\n",
    "- DataFrame\n",
    "- Series\n",
    "- Index\n",
    "\n",
    "## Series\n",
    "\n",
    "One-dimensional - represents a single column or row of data.  Only has one Index\n",
    "\n",
    "## DataFrame\n",
    "\n",
    "Two-dimensional.  Has both row and column labels (two Indexes)\n",
    "\n",
    "## Index\n",
    "\n",
    "This represents the row or column labels in Series and DataFrames\n",
    "\n",
    "![DataFrame Vs Series](DataFrameVsSeries_.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print planes.columns\n",
    "print type(planes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Indexing\n",
    "\n",
    "You can grab a single column using\n",
    "```\n",
    "dataframe[column_name]\n",
    "```\n",
    "\n",
    "To grab a row, use:\n",
    "```\n",
    "dataframe.loc[row_name]\n",
    "```\n",
    "\n",
    "And to grab a specific element use:\n",
    "```\n",
    "dataframe.loc[row_name, column_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes.head(10) # show just the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes['manufacturer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print type(planes['manufacturer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you grab a single column, you have a series\n",
    "\n",
    "![ColumnIndex](ColumnIndex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowthree = planes.loc[3]  # We use 3 because the row index is just numbers right now\n",
    "print rowthree\n",
    "print type(rowthree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the row is a 'Series', and it has its own index - the same as the columns of the data frame!\n",
    "\n",
    "![Row Indexing](RowIndex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe index\n",
    "\n",
    "So far the row-index has been numeric (just 0 through ~3300).  However, we might want to use labels here too.\n",
    "\n",
    "To do this, we can select a column to be the dataframe's index\n",
    "**Only do this if the column contains unique data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes.head(5) # Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "planes = planes.set_index('tailnum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes.head(5) # After"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the index column when you read the file in:\n",
    "\n",
    "```python\n",
    "planes = pd.read_table('planes.txt', index_col=0) #Set the first column as the index\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can grab a row by name:\n",
    "planes.loc['N10156']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also use .loc to grab a single value\n",
    "\n",
    "print planes.loc['N10156', 'model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But now how do I get the 3rd row since we changed the index to tail-numbers?\n",
    "\n",
    "Here's where **iloc** comes into play.\n",
    "\n",
    "Works like **loc** but uses integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print planes.iloc[3] # Get the third row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print planes.iloc[:, 3] # Get the third column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Indexing: In-summary\n",
    "\n",
    "You can grab a single column using\n",
    "```python\n",
    "dataframe[column_name]\n",
    "```\n",
    "\n",
    "To grab a row, use:\n",
    "```python\n",
    "dataframe.loc[row_name]\n",
    "```\n",
    "\n",
    "And to grab a specific element use:\n",
    "```python\n",
    "dataframe.loc[row_name, column_name]\n",
    "```\n",
    "\n",
    "If you want to grab rows or column based on their position, use:\n",
    "```python\n",
    "dataframe.iloc[row_number or :, column_number or :]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's explore the 'flights' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flights = pd.read_table(\"nycflights13/flights.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head(5) # first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.tail(5) # last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.sample(5) # random 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform functions along an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average air_time across all flights\n",
    "flights['air_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = flights[['air_time', 'dep_delay', 'arr_delay']]  # Grab only these three columns\n",
    "subset.mean(axis=0)  # Take mean across all rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to mean, there's also:\n",
    "- min\n",
    "- max\n",
    "- median\n",
    "- sum\n",
    "- var (for variance)\n",
    "- std (for standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also `sort_values` to sort by one or more columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.sort_values(\"air_time\").head(10)\n",
    "\n",
    "# Shortest flights are only ~20 minutes from NYC to Philadelphia or Connecticut!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.sort_values(['year', 'month', 'day', 'hour', 'minute']).head(10)\n",
    "\n",
    "# Sorts by year, then by month, then by day....and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**unique()** is useful for checking out the values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['origin'].unique()  # Three departure airports in the NYC area in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting specific rows\n",
    "\n",
    "What if we wanted to find the average departure delay for each of the three airports?\n",
    "\n",
    "A few ways we could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewr_delays = []\n",
    "lga_delays = []\n",
    "jfk_delays = []\n",
    "\n",
    "for i in flights.sample(10000).index:  # Only running over a small part, this takes ~2 minutes over the whole thing!\n",
    "    row = flights.loc[i]\n",
    "    origin = row['origin']\n",
    "    delay = row['dep_delay']\n",
    "    \n",
    "    if pd.isnull(delay): continue   #  Skip NaNs\n",
    "        \n",
    "    if origin == 'JFK':\n",
    "        jfk_delays.append(delay)\n",
    "    if origin == 'EWR':\n",
    "        ewr_delays.append(delay)\n",
    "    if origin == 'LGA':\n",
    "        lga_delays.append(delay)\n",
    "        \n",
    "print 'JFK Delay: ', sum(jfk_delays) / len(jfk_delays)\n",
    "print 'EWR Delay: ', sum(ewr_delays) / len(ewr_delays)\n",
    "print 'LGA Delay: ', sum(lga_delays) / len(lga_delays)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A better way\n",
    "\n",
    "lga_rows = (flights['origin'] == 'LGA')\n",
    "print lga_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jfk_delays = flights.loc[flights['origin'] == 'JFK', 'dep_delay']\n",
    "ewr_delays = flights.loc[flights['origin'] == 'EWR', 'dep_delay']\n",
    "lga_delays = flights.loc[flights['origin'] == 'LGA', 'dep_delay']\n",
    "\n",
    "print 'JFK Delay: ', jfk_delays.mean()  # pandas mean ignores NaNs by default\n",
    "print 'EWR Delay: ', ewr_delays.mean()\n",
    "print 'LGA Delay: ', lga_delays.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice and all, but what if there were 100 origins?  \n",
    "\n",
    "Wouldn't want to write 100 lines here!\n",
    "\n",
    "\n",
    "### Using Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one statement\n",
    "flights.groupby('origin')['dep_delay'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's happening here?\n",
    "\n",
    "![GroupByExample](GroupBy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Could group by another variable - with more levels\n",
    "flights.groupby('carrier')['dep_delay'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging\n",
    "\n",
    "Merging provides a way to combine two tables together based on the data in them\n",
    "\n",
    "To demonstrate this, we'll look at combining the planes and flights tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that planes has 'tailnum' as an index\n",
    "planes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flights has a column for tailnum - every flight corresponds to a row in planes\n",
    "flights.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to know how many seats (total) were on flights that took off on february first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, subset flights to just have rows for february first\n",
    "\n",
    "feb1_flights = flights.loc[ (flights.month == 2) & (flights.day == 1)]\n",
    "\n",
    "feb1_flights.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to merge the two tables together.  For every row in flights, we're going to add in columns from planes from the row that matches the flights 'tailnum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb1_flights_w_planes = feb1_flights.merge(planes, left_on='tailnum', right_index=True)\n",
    "feb1_flights_w_planes.head(10) # Let's look at the resulting table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this statement:\n",
    "\n",
    "```python\n",
    "feb1_flights.merge(planes, left_on='tailnum', right_index=True)\n",
    "```\n",
    "\n",
    "'left' refers to the first dataframe (feb1_flights), and 'right' refers to the second dataframe (planes)\n",
    "\n",
    "`left_on='tailnum'` means:  Use the 'tailnum' column for the feb1_flights dataframe\n",
    "\n",
    "We could also supply `right_on` to tell it what column to use in the planes dataframe, but since we want the index, we use `right_index=True` instead (you can't do `right_on='Index'` because what if a column was named Index?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can answer our question now by summing the 'seats' column, which came from the 'planes' table\n",
    "\n",
    "print feb1_flights_w_planes['seats'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of seats!  \n",
    "\n",
    "Just for flights leaving three airports in the NYC area on one day.\n",
    "\n",
    "I'm sure all the flights weren't full, but I bet they real number of people departing is at least 80% of that figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to file\n",
    "\n",
    "Pandas makes writing the results to a file very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to a CSV (comma-seperated value) file\n",
    "\n",
    "# top 20 rows\n",
    "top = flights.head(20)\n",
    "top.to_csv(\"flights_top.csv\")\n",
    "\n",
    "top.to_csv(\"flights_top.csv\", sep=\"\\t\")  # Use tab as a separator instead of comma\n",
    "\n",
    "\n",
    "top.to_excel(\"flights_top.xlsx\", sheet_name='FlightsTop')  # Use tab as a separator instead of comma\n",
    "\n",
    "# You might need to install the openpyxl module for Excel writing to work\n",
    "# To do this, open a terminal and type in \"conda install openpyxl\", then restart the jupyter notebook by\n",
    "# going to Kernel (at the top) and selecting 'Restart'.  You will have to re-run the earlier cells that load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<ol start=\"3\">\n",
    "<li style=\"margin-bottom: 20px\"><b>Does rain cause airline delays?</b><br/>\n",
    "Let's see if we can use the data to answer this question - does rain cause airline delays?\n",
    "    <ol>\n",
    "        <li>\n",
    "Load the `nycflights13/weather.txt` table.  Investigate the precip column - find out the average amount of precipitation when the precipitation is not 0.  Also find the standard deviation of the precipitation (but only in the hours when it isn't zero).\n",
    "        </li>\n",
    "        <li>\n",
    "Merge the 'flights' table from earlier with the 'weather' table on the ['year', 'month', 'day', 'hour', 'origin'] columns.  This will give you weather information for each flight.  Select only the 'dep_delay' and 'precip' columns so you have a table with only two columns.\n",
    "        </li>\n",
    "        <li>\n",
    "Select only the rows where precip == 0.  What is the average dep_delay for these rows?  What about the dep_delay where there is high precipitation (use a cutoff where \"high precipitation\" is precipitation that is greater than the mean + 1 standard deviation as calculated in part 1a).\n",
    "        </li>\n",
    "        <li>\n",
    "There's a difference in delay from part 1c, but is it significant?  Use Google to look up the ranksums function from scipy and use it to test whether the delays from the No-Precipitation group are significantly different than the delays in the High-Precipitation group.\n",
    "        </li>\n",
    "    </ol>\n",
    "</li>\n",
    "\n",
    "<li style=\"margin-bottom: 20px\"><b>Explore</b><br/>\n",
    "Check out the tables and see if there is another question you could ask and try to answer.\n",
    "</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
